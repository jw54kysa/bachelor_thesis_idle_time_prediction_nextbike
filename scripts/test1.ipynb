{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import wandb\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2037726, 11)\n",
      "(2037726, 1)\n",
      "(509432, 11)\n",
      "(509432, 1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/df_points/final_df_points_18_21.csv')\n",
    "TargetVariable=['idle_time']\n",
    "Predictors=['bike_id', 'lat', 'lng', 'temp', 'rain', 'snow', 'dt_start','hex_enc','start_min', 'month', 'day']\n",
    "\n",
    "X=df[Predictors].values\n",
    "y=df[TargetVariable].values\n",
    "\n",
    "### Sandardization of data ###\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "PredictorScaler=StandardScaler()\n",
    "TargetVarScaler=StandardScaler()\n",
    "\n",
    "# Storing the fit object for later reference\n",
    "PredictorScalerFit=PredictorScaler.fit(X)\n",
    "TargetVarScalerFit=TargetVarScaler.fit(y)\n",
    "\n",
    "# Generating the standardized values of X and y\n",
    "X=PredictorScalerFit.transform(X)\n",
    "y=TargetVarScalerFit.transform(y)\n",
    "\n",
    "\n",
    "# Split the data into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Quick sanity check with the shapes of Training and testing datasets\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mjonathanweske\u001B[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.12.11"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/Users/jonweske/devment/BA_nextbike/scripts/wandb/run-20220331_141920-3npl8303</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/jonathanweske/test/runs/3npl8303\" target=\"_blank\">fluent-silence-1</a></strong> to <a href=\"https://wandb.ai/jonathanweske/test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/jonathanweske/test/runs/3npl8303?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x7f9057290f10>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"test\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.25562574\n",
      "Validation score: 0.497142\n",
      "Iteration 2, loss = 0.24810027\n",
      "Validation score: 0.507883\n",
      "Iteration 3, loss = 0.24324494\n",
      "Validation score: 0.519172\n",
      "Iteration 4, loss = 0.23848565\n",
      "Validation score: 0.527648\n",
      "Iteration 5, loss = 0.23612109\n",
      "Validation score: 0.532093\n",
      "Iteration 6, loss = 0.23414065\n",
      "Validation score: 0.534370\n",
      "Iteration 7, loss = 0.23155038\n",
      "Validation score: 0.539917\n",
      "Iteration 8, loss = 0.22931518\n",
      "Validation score: 0.539037\n",
      "Iteration 9, loss = 0.22747935\n",
      "Validation score: 0.547469\n",
      "Iteration 10, loss = 0.22583394\n",
      "Validation score: 0.548324\n",
      "Iteration 11, loss = 0.22466977\n",
      "Validation score: 0.551041\n",
      "Iteration 12, loss = 0.22368536\n",
      "Validation score: 0.550613\n",
      "Iteration 13, loss = 0.22292672\n",
      "Validation score: 0.556469\n",
      "Iteration 14, loss = 0.22209682\n",
      "Validation score: 0.556476\n",
      "Iteration 15, loss = 0.22146757\n",
      "Validation score: 0.558363\n",
      "Iteration 16, loss = 0.22095130\n",
      "Validation score: 0.552878\n",
      "Iteration 17, loss = 0.22054234\n",
      "Validation score: 0.557451\n",
      "Iteration 18, loss = 0.22014583\n",
      "Validation score: 0.558105\n",
      "Iteration 19, loss = 0.21986800\n",
      "Validation score: 0.558192\n",
      "Iteration 20, loss = 0.21964224\n",
      "Validation score: 0.558053\n",
      "Iteration 21, loss = 0.21935047\n",
      "Validation score: 0.561836\n",
      "Iteration 22, loss = 0.21913911\n",
      "Validation score: 0.561222\n",
      "Iteration 23, loss = 0.21897331\n",
      "Validation score: 0.559520\n",
      "Iteration 24, loss = 0.21879492\n",
      "Validation score: 0.563437\n",
      "Iteration 25, loss = 0.21862757\n",
      "Validation score: 0.561493\n",
      "Iteration 26, loss = 0.21834411\n",
      "Validation score: 0.563349\n",
      "Iteration 27, loss = 0.21836587\n",
      "Validation score: 0.564415\n",
      "Iteration 28, loss = 0.21813039\n",
      "Validation score: 0.561384\n",
      "Iteration 29, loss = 0.21798269\n",
      "Validation score: 0.563262\n",
      "Iteration 30, loss = 0.21789327\n",
      "Validation score: 0.565319\n",
      "Iteration 31, loss = 0.21779158\n",
      "Validation score: 0.562177\n",
      "Iteration 32, loss = 0.21760545\n",
      "Validation score: 0.564072\n",
      "Iteration 33, loss = 0.21759494\n",
      "Validation score: 0.566665\n",
      "Iteration 34, loss = 0.21749247\n",
      "Validation score: 0.562611\n",
      "Iteration 35, loss = 0.21731399\n",
      "Validation score: 0.565120\n",
      "Iteration 36, loss = 0.21720982\n",
      "Validation score: 0.564572\n",
      "Iteration 37, loss = 0.21708422\n",
      "Validation score: 0.566568\n",
      "Iteration 38, loss = 0.21697431\n",
      "Validation score: 0.564826\n",
      "Iteration 39, loss = 0.21696649\n",
      "Validation score: 0.563686\n",
      "Iteration 40, loss = 0.21682662\n",
      "Validation score: 0.566508\n",
      "Iteration 41, loss = 0.21675042\n",
      "Validation score: 0.566136\n",
      "Iteration 42, loss = 0.21666786\n",
      "Validation score: 0.568037\n",
      "Iteration 43, loss = 0.21667439\n",
      "Validation score: 0.565955\n",
      "Iteration 44, loss = 0.21656455\n",
      "Validation score: 0.569357\n",
      "Iteration 45, loss = 0.21647813\n",
      "Validation score: 0.565179\n",
      "Iteration 46, loss = 0.21640236\n",
      "Validation score: 0.567268\n",
      "Iteration 47, loss = 0.21631541\n",
      "Validation score: 0.568662\n",
      "Iteration 48, loss = 0.21623071\n",
      "Validation score: 0.569359\n",
      "Iteration 49, loss = 0.21616834\n",
      "Validation score: 0.567516\n",
      "Iteration 50, loss = 0.21613158\n",
      "Validation score: 0.566277\n",
      "Iteration 51, loss = 0.21607416\n",
      "Validation score: 0.568281\n",
      "Iteration 52, loss = 0.21601599\n",
      "Validation score: 0.569083\n",
      "Iteration 53, loss = 0.21593579\n",
      "Validation score: 0.569515\n",
      "Iteration 54, loss = 0.21588645\n",
      "Validation score: 0.563900\n",
      "Iteration 55, loss = 0.21577927\n",
      "Validation score: 0.567967\n",
      "Iteration 56, loss = 0.21574964\n",
      "Validation score: 0.566209\n",
      "Iteration 57, loss = 0.21577480\n",
      "Validation score: 0.568539\n",
      "Iteration 58, loss = 0.21568439\n",
      "Validation score: 0.569548\n",
      "Iteration 59, loss = 0.21568015\n",
      "Validation score: 0.568229\n",
      "Iteration 60, loss = 0.21556355\n",
      "Validation score: 0.569033\n",
      "Iteration 61, loss = 0.21551970\n",
      "Validation score: 0.570135\n",
      "Iteration 62, loss = 0.21549979\n",
      "Validation score: 0.569284\n",
      "Iteration 63, loss = 0.21539223\n",
      "Validation score: 0.569367\n",
      "Iteration 64, loss = 0.21533648\n",
      "Validation score: 0.567630\n",
      "Iteration 65, loss = 0.21534150\n",
      "Validation score: 0.569732\n",
      "Iteration 66, loss = 0.21527724\n",
      "Validation score: 0.570044\n",
      "Iteration 67, loss = 0.21521693\n",
      "Validation score: 0.569871\n",
      "Iteration 68, loss = 0.21516150\n",
      "Validation score: 0.568943\n",
      "Iteration 69, loss = 0.21512732\n",
      "Validation score: 0.570397\n",
      "Iteration 70, loss = 0.21513508\n",
      "Validation score: 0.570561\n",
      "Iteration 71, loss = 0.21503678\n",
      "Validation score: 0.569163\n",
      "Iteration 72, loss = 0.21499777\n",
      "Validation score: 0.570876\n",
      "Iteration 73, loss = 0.21496026\n",
      "Validation score: 0.569587\n",
      "Iteration 74, loss = 0.21491697\n",
      "Validation score: 0.572540\n",
      "Iteration 75, loss = 0.21486525\n",
      "Validation score: 0.570168\n",
      "Iteration 76, loss = 0.21484816\n",
      "Validation score: 0.571203\n",
      "Iteration 77, loss = 0.21481012\n",
      "Validation score: 0.569264\n",
      "Iteration 78, loss = 0.21475907\n",
      "Validation score: 0.570004\n",
      "Iteration 79, loss = 0.21465799\n",
      "Validation score: 0.568271\n",
      "Iteration 80, loss = 0.21462369\n",
      "Validation score: 0.568697\n",
      "Iteration 81, loss = 0.21459526\n",
      "Validation score: 0.569244\n",
      "Iteration 82, loss = 0.21460453\n",
      "Validation score: 0.570374\n",
      "Iteration 83, loss = 0.21457921\n",
      "Validation score: 0.571466\n",
      "Iteration 84, loss = 0.21449562\n",
      "Validation score: 0.571486\n",
      "Iteration 85, loss = 0.21442284\n",
      "Validation score: 0.572740\n",
      "Iteration 86, loss = 0.21449366\n",
      "Validation score: 0.572629\n",
      "Iteration 87, loss = 0.21440717\n",
      "Validation score: 0.571497\n",
      "Iteration 88, loss = 0.21436168\n",
      "Validation score: 0.571713\n",
      "Iteration 89, loss = 0.21432956\n",
      "Validation score: 0.569622\n",
      "Iteration 90, loss = 0.21425869\n",
      "Validation score: 0.571657\n",
      "Iteration 91, loss = 0.21434098\n",
      "Validation score: 0.570562\n",
      "Iteration 92, loss = 0.21427692\n",
      "Validation score: 0.570500\n",
      "Iteration 93, loss = 0.21417486\n",
      "Validation score: 0.571119\n",
      "Iteration 94, loss = 0.21418917\n",
      "Validation score: 0.569852\n",
      "Iteration 95, loss = 0.21418424\n",
      "Validation score: 0.570836\n",
      "Iteration 96, loss = 0.21410688\n",
      "Validation score: 0.569071\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "nn = MLPRegressor(hidden_layer_sizes=(64,32,16), activation='tanh', solver='adam', verbose=1, early_stopping=True)\n",
    "nn.fit(X_train,y_train.ravel())\n",
    "\n",
    "expected_y = y_test\n",
    "predicted_y = nn.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# log wand shit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}