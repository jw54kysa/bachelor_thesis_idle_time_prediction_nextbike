{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3ed9e1a",
   "metadata": {},
   "source": [
    "# df_points with UNIX Timestamp #\n",
    "## Creates df_points.csv with all points and idletimes #\n",
    "## Checks the valid geo location\n",
    "## deletes the invalid points: \n",
    "2019 - ca. 9.5%\n",
    "\n",
    "2020 - ca. 2.7%\n",
    "\n",
    "2021 - ca.\n",
    "\n",
    "### ca 1h for 1 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a791a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importdata(source):\n",
    "    df = pd.read_csv(source)\n",
    "    df = df[['bike_id', 'start_time', 'end_time', 'start_lat', 'start_lng', 'end_lat', 'end_lng']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82359632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicOutOfDf(df01):\n",
    "    import pandas as pd\n",
    "    from tqdm import tqdm\n",
    "    # Dict out of DataFrames of Trips per Bike\n",
    "\n",
    "    # init DFs for every bike\n",
    "    myDFs = {}\n",
    "\n",
    "    for ind in tqdm(df01.index):\n",
    "        if df01['bike_id'][ind] not in myDFs:\n",
    "            myDFs[df01['bike_id'][ind]] = pd.DataFrame(\n",
    "                columns=['bike_id', 'start_time', 'end_time', 'start_lat', 'start_lng', 'end_lat', 'end_lng'])\n",
    "    return myDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "941271a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addRentalsToDf(df01,myDFs):\n",
    "    from tqdm import tqdm\n",
    "    # Add all rentals to their bike_id DF\n",
    "    for ind in tqdm(df01.index):\n",
    "        if df01['bike_id'][ind] in myDFs:\n",
    "            myDFs[df01['bike_id'][ind]].loc[df01.index[ind]] = df01.iloc[ind]\n",
    "    return myDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3502fb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortDFs(myDFs):\n",
    "    # sort every DF\n",
    "    for df in myDFs.values():\n",
    "        df[['bike_id', 'start_time','end_time']] = df[['bike_id', 'start_time','end_time']].astype(int)\n",
    "        df[['start_lat','start_lng', 'end_lat', 'end_lng']] = df[['start_lat','start_lng', 'end_lat', 'end_lng']].astype(float)\n",
    "        df.sort_values(by=['start_time'], inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "    return myDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b82d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfPoints(myDFs,radius):\n",
    "    # DF of all points with stoodtime\n",
    "    inval = 0\n",
    "    val = 0 \n",
    "    \n",
    "    df_points = pd.DataFrame(columns=['bike_id', 'lat', 'lng', 'timestood', 'time_start', 'time_end'])\n",
    "    df_points[['bike_id', 'timestood', 'time_start', 'time_end']] = df_points[['bike_id', 'timestood', 'time_start', 'time_end']].astype(int)\n",
    "    df_points[['lng', 'lat']] = df_points[['lng', 'lat']].astype(float)\n",
    "    \n",
    "    for df in tqdm(myDFs.values()):\n",
    "        for ind in df.index[1:]:\n",
    "            #in SECOUNDS\n",
    "            timestood = (df['start_time'][ind] - df['end_time'][ind - 1]).astype(int)\n",
    "            distance = qick_distance(df['end_lat'][ind-1], df['end_lng'][ind-1], df['start_lat'][ind], df['start_lng'][ind])\n",
    "            if distance > radius:\n",
    "                inval +=1\n",
    "                continue\n",
    "            val +=1\n",
    "            dict = {'bike_id': df['bike_id'][ind], 'lng': df['start_lng'][ind], 'lat': df['start_lat'][ind],\n",
    "                    'timestood': timestood, 'time_start': df['end_time'][ind - 1], 'time_end': df['start_time'][ind]}\n",
    "            df_points = df_points.append(dict, ignore_index=True)\n",
    "    print(f\"invalides: {inval} from {val} thats {inval/val * 100} %\")\n",
    "    return df_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e34af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns distance in meter\n",
    "# source: https://www.it-swarm.com.de/de/python/wie-kann-ich-die-entfernung-zwischen-zwei-punkten-breitengrad-laengengrad-schnell-schaetzen/1072488907/\n",
    "def qick_distance(Lat1, Long1, Lat2, Long2):\n",
    "    x = Lat2 - Lat1\n",
    "    y = (Long2 - Long1)*cos((Lat2 + Lat1)*0.00872664626)  \n",
    "    return 111.138*sqrt(x*x+y*y)*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edc119ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keplerMap(df_points):\n",
    "    heatmap = KeplerGl()\n",
    "    heatmap.add_data(data=df_points, name='points')\n",
    "    heatmap.save_to_html(file_name='heatmap_test.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4cd011",
   "metadata": {},
   "source": [
    "# Main \n",
    "## Create map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e341a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 571894/571894 [00:04<00:00, 120450.57it/s]\n",
      "100%|██████████| 571894/571894 [14:24<00:00, 661.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from keplergl import KeplerGl\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "from tqdm import tqdm\n",
    "from geopy.distance import geodesic\n",
    "import h3\n",
    "\n",
    "source = '../data/raw_lendings/lendings_2021.csv'\n",
    "\n",
    "df = importdata(source)\n",
    "myDfs = dicOutOfDf(df)\n",
    "myDfs = addRentalsToDf(df, myDfs)\n",
    "myDfs = sortDFs(myDfs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e6afa9",
   "metadata": {},
   "source": [
    "## Save MyDfs Map to file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc02e73",
   "metadata": {},
   "source": [
    "import pickle\n",
    "with open('saved_myDfs_2019.pkl', 'wb') as f:\n",
    "    pickle.dump(myDfs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b3a096",
   "metadata": {},
   "source": [
    "## Create DF_points \n",
    "### without invalid points\n",
    "52523 from 550865"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3440ce0d",
   "metadata": {},
   "source": [
    "def importMyDFsDic():\n",
    "    with open('../data/saved_myDfs.pkl', 'rb') as f:\n",
    "        myDfs = pickle.load(f)\n",
    "    return myDfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2c1891",
   "metadata": {},
   "source": [
    "### ggf Map from file importieren\n",
    "import pickle\n",
    "myDf_imported = importMyDFsDic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fae31aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1203/1203 [39:35<00:00,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalides: 21842 from 548849 thats 3.979600946708475 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create DF_POints\n",
    "from math import cos, sqrt\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "radius = 20\n",
    "df_points = dfPoints(myDfs,radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1724f5",
   "metadata": {},
   "source": [
    "## Save df_points_valid_geov01.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada7aabe",
   "metadata": {},
   "source": [
    "df_points.to_csv(\"../data/df_points_2019_v1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50748b61",
   "metadata": {},
   "source": [
    "# Split Points at midnight\n",
    "\n",
    "## save flag feature & time_stood_next_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a6fc960",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_points['timestood'] = pd.to_timedelta(df_points['timestood'],unit='s')\n",
    "df_points['time_start'] = pd.to_datetime(df_points['time_start'],unit='s')\n",
    "df_points['time_end'] = pd.to_datetime(df_points['time_end'],unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8395e5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548849/548849 [1:42:20<00:00, 89.38it/s]  \n",
      "100%|██████████| 687103/687103 [22:30<00:00, 508.80it/s]  \n",
      "100%|██████████| 712509/712509 [10:29<00:00, 1132.15it/s] \n",
      "100%|██████████| 723768/723768 [05:55<00:00, 2033.85it/s] \n",
      "100%|██████████| 729880/729880 [03:51<00:00, 3157.37it/s] \n",
      "100%|██████████| 733671/733671 [02:43<00:00, 4489.97it/s] \n",
      "100%|██████████| 736184/736184 [02:03<00:00, 5981.91it/s] \n",
      "100%|██████████| 737940/737940 [01:40<00:00, 7375.61it/s] \n",
      "100%|██████████| 739229/739229 [01:25<00:00, 8635.13it/s] \n",
      "100%|██████████| 740212/740212 [01:12<00:00, 10168.15it/s]\n",
      "100%|██████████| 740973/740973 [01:05<00:00, 11391.56it/s]\n",
      "100%|██████████| 741563/741563 [00:57<00:00, 12822.18it/s]\n",
      "100%|██████████| 742029/742029 [00:52<00:00, 14188.88it/s]\n",
      "100%|██████████| 742393/742393 [00:49<00:00, 15050.67it/s]\n",
      "100%|██████████| 742698/742698 [00:45<00:00, 16371.02it/s]\n",
      "100%|██████████| 742949/742949 [00:43<00:00, 16955.79it/s]\n",
      "100%|██████████| 743151/743151 [00:41<00:00, 18002.86it/s]\n",
      "100%|██████████| 743323/743323 [00:40<00:00, 18276.61it/s]\n",
      "100%|██████████| 743466/743466 [00:41<00:00, 18117.67it/s]\n",
      "100%|██████████| 743579/743579 [00:38<00:00, 19121.70it/s]\n",
      "100%|██████████| 743677/743677 [00:36<00:00, 20131.22it/s]\n",
      "100%|██████████| 743752/743752 [00:36<00:00, 20598.15it/s]\n",
      "100%|██████████| 743816/743816 [00:35<00:00, 20839.28it/s]\n",
      "100%|██████████| 743875/743875 [00:36<00:00, 20387.25it/s]\n",
      "100%|██████████| 743925/743925 [00:34<00:00, 21276.74it/s]\n",
      "100%|██████████| 743969/743969 [00:34<00:00, 21448.32it/s]\n",
      "100%|██████████| 744007/744007 [00:34<00:00, 21273.63it/s]\n",
      "100%|██████████| 744044/744044 [00:34<00:00, 21537.57it/s]\n",
      "100%|██████████| 744080/744080 [00:34<00:00, 21672.28it/s]\n",
      "100%|██████████| 744112/744112 [00:34<00:00, 21608.42it/s]\n",
      "100%|██████████| 744144/744144 [00:34<00:00, 21748.07it/s]\n",
      "100%|██████████| 744175/744175 [00:35<00:00, 20904.48it/s]\n",
      "100%|██████████| 744206/744206 [00:34<00:00, 21837.58it/s]\n",
      "100%|██████████| 744233/744233 [00:34<00:00, 21478.91it/s]\n",
      "100%|██████████| 744260/744260 [00:35<00:00, 21133.42it/s]\n",
      "100%|██████████| 744284/744284 [00:33<00:00, 22042.96it/s]\n",
      "100%|██████████| 744306/744306 [00:33<00:00, 22123.67it/s]\n",
      "100%|██████████| 744326/744326 [00:33<00:00, 22197.29it/s]\n",
      "100%|██████████| 744345/744345 [00:33<00:00, 22199.80it/s]\n",
      "100%|██████████| 744364/744364 [00:34<00:00, 21780.85it/s]\n",
      "100%|██████████| 744381/744381 [00:33<00:00, 22123.71it/s]\n",
      "100%|██████████| 744397/744397 [00:33<00:00, 22257.66it/s]\n",
      "100%|██████████| 744413/744413 [00:33<00:00, 22356.92it/s]\n",
      "100%|██████████| 744428/744428 [00:33<00:00, 22425.74it/s]\n",
      "100%|██████████| 744443/744443 [00:33<00:00, 22188.01it/s]\n",
      "100%|██████████| 744458/744458 [00:33<00:00, 22498.34it/s]\n",
      "100%|██████████| 744472/744472 [00:33<00:00, 22530.30it/s]\n",
      "100%|██████████| 744484/744484 [00:32<00:00, 22570.47it/s]\n",
      "100%|██████████| 744495/744495 [00:32<00:00, 22695.15it/s]\n",
      "100%|██████████| 744505/744505 [00:32<00:00, 22742.24it/s]\n",
      "100%|██████████| 744513/744513 [00:32<00:00, 22743.11it/s]\n",
      "100%|██████████| 744520/744520 [00:32<00:00, 22732.53it/s]\n",
      "100%|██████████| 744527/744527 [00:32<00:00, 22740.98it/s]\n",
      "100%|██████████| 744533/744533 [00:34<00:00, 21837.64it/s]\n",
      "100%|██████████| 744539/744539 [00:35<00:00, 20985.86it/s]\n",
      "100%|██████████| 744545/744545 [00:34<00:00, 21561.06it/s]\n",
      "100%|██████████| 744551/744551 [00:34<00:00, 21857.51it/s]\n",
      "100%|██████████| 744557/744557 [00:36<00:00, 20132.34it/s]\n",
      "100%|██████████| 744562/744562 [00:34<00:00, 21634.76it/s]\n",
      "100%|██████████| 744567/744567 [00:34<00:00, 21761.87it/s]\n",
      "100%|██████████| 744572/744572 [00:34<00:00, 21710.65it/s]\n",
      "100%|██████████| 744577/744577 [00:35<00:00, 21020.89it/s]\n",
      "100%|██████████| 744581/744581 [00:34<00:00, 21734.13it/s]\n",
      "100%|██████████| 744584/744584 [00:34<00:00, 21834.17it/s]\n",
      "100%|██████████| 744587/744587 [00:33<00:00, 22007.82it/s]\n",
      "100%|██████████| 744590/744590 [00:34<00:00, 21622.52it/s]\n",
      "100%|██████████| 744593/744593 [00:34<00:00, 21776.49it/s]\n",
      "100%|██████████| 744596/744596 [00:35<00:00, 21200.82it/s]\n",
      "100%|██████████| 744598/744598 [00:34<00:00, 21782.08it/s]\n",
      "100%|██████████| 744600/744600 [00:34<00:00, 21783.52it/s]\n",
      "100%|██████████| 744602/744602 [00:34<00:00, 21677.78it/s]\n",
      "100%|██████████| 744604/744604 [00:34<00:00, 21507.49it/s]\n",
      "100%|██████████| 744606/744606 [00:34<00:00, 21780.66it/s]\n",
      "100%|██████████| 744608/744608 [00:34<00:00, 21510.22it/s]\n",
      "100%|██████████| 744610/744610 [00:34<00:00, 21470.45it/s]\n",
      "100%|██████████| 744612/744612 [00:34<00:00, 21620.41it/s]\n",
      "100%|██████████| 744614/744614 [00:34<00:00, 21637.47it/s]\n",
      "100%|██████████| 744616/744616 [00:34<00:00, 21587.59it/s]\n",
      "100%|██████████| 744618/744618 [00:34<00:00, 21667.11it/s]\n",
      "100%|██████████| 744619/744619 [00:34<00:00, 21348.69it/s]\n",
      "100%|██████████| 744620/744620 [00:34<00:00, 21614.36it/s]\n",
      "100%|██████████| 744621/744621 [00:34<00:00, 21673.22it/s]\n",
      "100%|██████████| 744622/744622 [00:34<00:00, 21608.17it/s]\n",
      "100%|██████████| 744623/744623 [00:34<00:00, 21658.07it/s]\n",
      "100%|██████████| 744624/744624 [00:34<00:00, 21428.11it/s]\n",
      "100%|██████████| 744625/744625 [00:34<00:00, 21580.34it/s]\n",
      "100%|██████████| 744626/744626 [00:34<00:00, 21627.62it/s]\n",
      "100%|██████████| 744627/744627 [00:34<00:00, 21623.16it/s]\n",
      "100%|██████████| 744628/744628 [00:34<00:00, 21503.14it/s]\n",
      "100%|██████████| 744629/744629 [00:34<00:00, 21388.93it/s]\n",
      "100%|██████████| 744630/744630 [00:34<00:00, 21548.72it/s]\n",
      "100%|██████████| 744631/744631 [00:34<00:00, 21640.37it/s]\n",
      "100%|██████████| 744632/744632 [00:34<00:00, 21602.16it/s]\n",
      "100%|██████████| 744633/744633 [00:34<00:00, 21634.40it/s]\n",
      "100%|██████████| 744634/744634 [00:34<00:00, 21771.27it/s]\n",
      "100%|██████████| 744635/744635 [00:34<00:00, 21762.00it/s]\n",
      "100%|██████████| 744636/744636 [00:35<00:00, 20710.94it/s]\n",
      "100%|██████████| 744637/744637 [00:33<00:00, 22559.40it/s]\n",
      "100%|██████████| 744638/744638 [00:32<00:00, 22797.29it/s]\n",
      "100%|██████████| 744639/744639 [00:32<00:00, 22662.43it/s]\n",
      "100%|██████████| 744640/744640 [00:32<00:00, 22774.40it/s]\n",
      "100%|██████████| 744641/744641 [00:32<00:00, 22798.49it/s]\n",
      "100%|██████████| 744642/744642 [00:32<00:00, 22806.57it/s]\n",
      "100%|██████████| 744643/744643 [00:32<00:00, 22743.59it/s]\n",
      "100%|██████████| 744644/744644 [00:32<00:00, 22854.08it/s]\n",
      "100%|██████████| 744645/744645 [00:32<00:00, 22584.31it/s]\n",
      "100%|██████████| 744646/744646 [00:32<00:00, 22824.15it/s]\n",
      "100%|██████████| 744647/744647 [00:32<00:00, 22743.20it/s]\n",
      "100%|██████████| 744648/744648 [00:44<00:00, 16879.05it/s]\n",
      "100%|██████████| 744649/744649 [00:43<00:00, 17131.35it/s]\n",
      "100%|██████████| 744650/744650 [00:44<00:00, 16551.03it/s]\n",
      "100%|██████████| 744651/744651 [00:48<00:00, 15341.71it/s]\n",
      "100%|██████████| 744652/744652 [00:35<00:00, 21141.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "\n",
    "changed = 1\n",
    "iterations = 0\n",
    "\n",
    "df_points['next_day_idle_time'] = np.nan\n",
    "\n",
    "while changed:\n",
    "    iterations += 1\n",
    "    changed = 0\n",
    "    for ind in tqdm(df_points.index):\n",
    "        ts = df_points['time_start'][ind]\n",
    "        te = df_points['time_end'][ind]\n",
    "        t0 = ts.replace(hour=23, minute=59, second=59)\n",
    "        \n",
    "        # is timestood greater than same date 23:59:59\n",
    "        #   -> over midnight\n",
    "        if ts + df_points['timestood'][ind] > t0:\n",
    "            changed = 1\n",
    "            \n",
    "            underhang = t0 - ts\n",
    "            overhang = te - t0\n",
    "            \n",
    "            # fix current day\n",
    "            df_points['time_end'][ind] = ts.replace(hour=23, minute=59, second=59)\n",
    "            df_points['timestood'][ind] = underhang\n",
    "            df_points['next_day_idle_time'][ind] = overhang\n",
    "            \n",
    "            # add new row for the next day\n",
    "            time_start = ts.replace(hour=0, minute=0, second=0)\n",
    "            time_start += timedelta(days=1)\n",
    "            flag = 0\n",
    "            if time_start + overhang > time_start.replace(hour=23, minute=59, second=59):\n",
    "                flag = 1\n",
    "            \n",
    "            dict = {'bike_id': df_points['bike_id'][ind], 'lng': df_points['lng'][ind], 'lat': df_points['lat'][ind],\n",
    "                    'timestood': overhang, 'time_start': time_start, 'time_end': te, 'flag' : flag, 'next_day_idle_time': np.nan}\n",
    "            df_points = df_points.append(dict, ignore_index=True)\n",
    "\n",
    "print(iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "   bike_id        lat        lng       timestood          time_start  \\\n0  75838.0  51.331022  12.316226 0 days 00:37:55 2020-12-31 23:22:04   \n1  75838.0  51.326178  12.334760 0 days 04:32:11 2021-01-04 19:27:48   \n2  75838.0  51.332178  12.343082 0 days 07:34:29 2021-01-05 05:34:11   \n3  75838.0  51.324615  12.336922 0 days 04:54:53 2021-01-05 13:13:36   \n4  75838.0  51.330267  12.336166 0 days 05:47:30 2021-01-05 18:12:29   \n\n             time_end next_day_idle_time  flag   idle_time  \n0 2020-12-31 23:59:59                NaN   NaN   37.916667  \n1 2021-01-04 23:59:59    0 days 05:29:32   NaN  272.183333  \n2 2021-01-05 13:08:40                NaN   NaN  454.483333  \n3 2021-01-05 18:08:29                NaN   NaN  294.883333  \n4 2021-01-05 23:59:59    0 days 07:32:36   NaN  347.500000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bike_id</th>\n      <th>lat</th>\n      <th>lng</th>\n      <th>timestood</th>\n      <th>time_start</th>\n      <th>time_end</th>\n      <th>next_day_idle_time</th>\n      <th>flag</th>\n      <th>idle_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>75838.0</td>\n      <td>51.331022</td>\n      <td>12.316226</td>\n      <td>0 days 00:37:55</td>\n      <td>2020-12-31 23:22:04</td>\n      <td>2020-12-31 23:59:59</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>37.916667</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>75838.0</td>\n      <td>51.326178</td>\n      <td>12.334760</td>\n      <td>0 days 04:32:11</td>\n      <td>2021-01-04 19:27:48</td>\n      <td>2021-01-04 23:59:59</td>\n      <td>0 days 05:29:32</td>\n      <td>NaN</td>\n      <td>272.183333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>75838.0</td>\n      <td>51.332178</td>\n      <td>12.343082</td>\n      <td>0 days 07:34:29</td>\n      <td>2021-01-05 05:34:11</td>\n      <td>2021-01-05 13:08:40</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>454.483333</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>75838.0</td>\n      <td>51.324615</td>\n      <td>12.336922</td>\n      <td>0 days 04:54:53</td>\n      <td>2021-01-05 13:13:36</td>\n      <td>2021-01-05 18:08:29</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>294.883333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>75838.0</td>\n      <td>51.330267</td>\n      <td>12.336166</td>\n      <td>0 days 05:47:30</td>\n      <td>2021-01-05 18:12:29</td>\n      <td>2021-01-05 23:59:59</td>\n      <td>0 days 07:32:36</td>\n      <td>NaN</td>\n      <td>347.500000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_points.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5aee7e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Timedelta\n",
    "# timestood to idle_time in MIN\n",
    "def f(row):\n",
    "    return row['timestood'].seconds / 60\n",
    "\n",
    "def v(row):\n",
    "    if row['next_day_idle_time'] == np.nan:\n",
    "        return 0\n",
    "    elif row['next_day_idle_time'].seconds < Timedelta(days=1).seconds:\n",
    "        return row['next_day_idle_time'].seconds / 60\n",
    "    else: return 1439\n",
    "\n",
    "df_points['idle_time'] = df_points.apply(f, axis=1)\n",
    "#df_points['next_day_idle_time'] = df_points.apply(v, axis=1)\n",
    "del df_points['timestood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3bf78e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_points['idle_time'] = df_points['idle_time'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3c97d2",
   "metadata": {},
   "source": [
    "# Save V2 df_points split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b29983",
   "metadata": {},
   "source": [
    "df_points.to_csv(\"../data/df_points_2019_v2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d901a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1439"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_points['idle_time'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "991143a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   bike_id        lat        lng          time_start            time_end  \\\n0  75838.0  51.331022  12.316226 2020-12-31 23:22:04 2020-12-31 23:59:59   \n1  75838.0  51.326178  12.334760 2021-01-04 19:27:48 2021-01-04 23:59:59   \n2  75838.0  51.332178  12.343082 2021-01-05 05:34:11 2021-01-05 13:08:40   \n3  75838.0  51.324615  12.336922 2021-01-05 13:13:36 2021-01-05 18:08:29   \n4  75838.0  51.330267  12.336166 2021-01-05 18:12:29 2021-01-05 23:59:59   \n\n  next_day_idle_time  flag  idle_time  \n0                NaN   NaN         37  \n1    0 days 05:29:32   NaN        272  \n2                NaN   NaN        454  \n3                NaN   NaN        294  \n4    0 days 07:32:36   NaN        347  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bike_id</th>\n      <th>lat</th>\n      <th>lng</th>\n      <th>time_start</th>\n      <th>time_end</th>\n      <th>next_day_idle_time</th>\n      <th>flag</th>\n      <th>idle_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>75838.0</td>\n      <td>51.331022</td>\n      <td>12.316226</td>\n      <td>2020-12-31 23:22:04</td>\n      <td>2020-12-31 23:59:59</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>75838.0</td>\n      <td>51.326178</td>\n      <td>12.334760</td>\n      <td>2021-01-04 19:27:48</td>\n      <td>2021-01-04 23:59:59</td>\n      <td>0 days 05:29:32</td>\n      <td>NaN</td>\n      <td>272</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>75838.0</td>\n      <td>51.332178</td>\n      <td>12.343082</td>\n      <td>2021-01-05 05:34:11</td>\n      <td>2021-01-05 13:08:40</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>454</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>75838.0</td>\n      <td>51.324615</td>\n      <td>12.336922</td>\n      <td>2021-01-05 13:13:36</td>\n      <td>2021-01-05 18:08:29</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>294</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>75838.0</td>\n      <td>51.330267</td>\n      <td>12.336166</td>\n      <td>2021-01-05 18:12:29</td>\n      <td>2021-01-05 23:59:59</td>\n      <td>0 days 07:32:36</td>\n      <td>NaN</td>\n      <td>347</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_points.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac57725",
   "metadata": {},
   "source": [
    "## Add H3 Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d822988",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 744652/744652 [00:15<00:00, 49533.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "   bike_id        lat        lng          time_start            time_end  \\\n0  75838.0  51.331022  12.316226 2020-12-31 23:22:04 2020-12-31 23:59:59   \n1  75838.0  51.326178  12.334760 2021-01-04 19:27:48 2021-01-04 23:59:59   \n2  75838.0  51.332178  12.343082 2021-01-05 05:34:11 2021-01-05 13:08:40   \n3  75838.0  51.324615  12.336922 2021-01-05 13:13:36 2021-01-05 18:08:29   \n4  75838.0  51.330267  12.336166 2021-01-05 18:12:29 2021-01-05 23:59:59   \n\n  next_day_idle_time  flag  idle_time           hex_id  \n0                NaN   NaN         37  881f1a8dd7fffff  \n1    0 days 05:29:32   NaN        272  881f1a8d91fffff  \n2                NaN   NaN        454  881f1a8d9bfffff  \n3                NaN   NaN        294  881f1a8d91fffff  \n4    0 days 07:32:36   NaN        347  881f1a8d9bfffff  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bike_id</th>\n      <th>lat</th>\n      <th>lng</th>\n      <th>time_start</th>\n      <th>time_end</th>\n      <th>next_day_idle_time</th>\n      <th>flag</th>\n      <th>idle_time</th>\n      <th>hex_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>75838.0</td>\n      <td>51.331022</td>\n      <td>12.316226</td>\n      <td>2020-12-31 23:22:04</td>\n      <td>2020-12-31 23:59:59</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>37</td>\n      <td>881f1a8dd7fffff</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>75838.0</td>\n      <td>51.326178</td>\n      <td>12.334760</td>\n      <td>2021-01-04 19:27:48</td>\n      <td>2021-01-04 23:59:59</td>\n      <td>0 days 05:29:32</td>\n      <td>NaN</td>\n      <td>272</td>\n      <td>881f1a8d91fffff</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>75838.0</td>\n      <td>51.332178</td>\n      <td>12.343082</td>\n      <td>2021-01-05 05:34:11</td>\n      <td>2021-01-05 13:08:40</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>454</td>\n      <td>881f1a8d9bfffff</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>75838.0</td>\n      <td>51.324615</td>\n      <td>12.336922</td>\n      <td>2021-01-05 13:13:36</td>\n      <td>2021-01-05 18:08:29</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>294</td>\n      <td>881f1a8d91fffff</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>75838.0</td>\n      <td>51.330267</td>\n      <td>12.336166</td>\n      <td>2021-01-05 18:12:29</td>\n      <td>2021-01-05 23:59:59</td>\n      <td>0 days 07:32:36</td>\n      <td>NaN</td>\n      <td>347</td>\n      <td>881f1a8d9bfffff</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h3\n",
    "\n",
    "#dfh3 = pd.read_csv('../data/df_points_2020_v2.csv')\n",
    "#dfh3['hex_id'] = 0\n",
    "#dfh3.head()\n",
    "\n",
    "df_points['hex_id'] = 0\n",
    "\n",
    "for ind in tqdm(df_points.index):\n",
    "    df_points['hex_id'][ind] = h3.geo_to_h3(df_points['lat'][ind], df_points['lng'][ind], 8)\n",
    "df_points.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a28483",
   "metadata": {},
   "source": [
    "# Add weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 571894/571894 [08:28<00:00, 1124.28it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'time_start'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/geobike/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3360\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3361\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3362\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/geobike/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/geobike/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'time_start'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/5t/28jzvs016nq5vxslb670gs040000gn/T/ipykernel_15311/2704820043.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m \u001B[0mdf_points\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'dt_start'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_datetime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'time_start'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTimestamp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtimestamp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     21\u001B[0m \u001B[0mdf_points\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'dt_end'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_datetime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'time_end'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTimestamp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtimestamp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[0mdf_points\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'bike_id'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf_points\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'bike_id'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/geobike/lib/python3.9/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3456\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3457\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3458\u001B[0;31m             \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3459\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3460\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/geobike/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3361\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3362\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3363\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3364\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3365\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mis_scalar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0misna\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhasnans\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'time_start'"
     ]
    }
   ],
   "source": [
    "dfw = pd.read_csv('../data/weather_data.csv')\n",
    "dfw['datetime'] = pd.to_datetime(dfw['dt'], unit='s')\n",
    "dfw = dfw.set_index(['datetime'])\n",
    "dfw.head()\n",
    "\n",
    "df_points['temp'] = np.nan\n",
    "df_points['rain'] = np.nan\n",
    "df_points['snow'] = np.nan\n",
    "\n",
    "from tqdm import tqdm\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "for ind in tqdm(df.index):\n",
    "    wint = df_points['time_start'][ind].replace(minute=0,second=0)\n",
    "    df_points['temp'][ind] = dfw['temp'][wint].copy()\n",
    "    df_points['rain'][ind] = dfw['rain_1h'][wint].copy()\n",
    "    df_points['snow'][ind] = dfw['snow_1h'][wint].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "df_points['dt_start'] = pd.to_datetime(df_points['time_start']).map(pd.Timestamp.timestamp).astype(int)\n",
    "df_points['dt_end'] = pd.to_datetime(df_points['time_end']).map(pd.Timestamp.timestamp).astype(int)\n",
    "df_points['bike_id'] = df_points['bike_id'].astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'time_start'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/geobike/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3360\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3361\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3362\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/geobike/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/geobike/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'time_start'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/5t/28jzvs016nq5vxslb670gs040000gn/T/ipykernel_15311/3203887387.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0mdf_points\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'idle_time_next_day'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf_points\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m \u001B[0;32mdel\u001B[0m \u001B[0mdf_points\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'time_start'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m \u001B[0;32mdel\u001B[0m \u001B[0mdf_points\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'time_end'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/geobike/lib/python3.9/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m__delitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3961\u001B[0m             \u001B[0;31m# there was no match, this call should raise the appropriate\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3962\u001B[0m             \u001B[0;31m# exception:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3963\u001B[0;31m             \u001B[0mloc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maxes\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3964\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_mgr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_mgr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0midelete\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3965\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/geobike/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3361\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3362\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3363\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3364\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3365\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mis_scalar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0misna\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhasnans\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'time_start'"
     ]
    }
   ],
   "source": [
    "#df_points['idle_time_next_day'] = pd.Timedelta(df_points['next_day_idle_time']).seconds.astype(int)\n",
    "def x(row):\n",
    "    tmp = pd.Timedelta(row['next_day_idle_time']).seconds / 60\n",
    "    if tmp < 1439:\n",
    "        return tmp\n",
    "    else: return 1439\n",
    "\n",
    "df_points['next_day_idle_time'] = df_points.apply(x,axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "del df_points['time_start']\n",
    "del df_points['time_end']\n",
    "del df_points['next_day_idle_time']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "   bike_id        lat        lng  flag  idle_time           hex_id  temp  \\\n0    75838  51.331022  12.316226   NaN         37  881f1a8dd7fffff  2.72   \n1    75838  51.326178  12.334760   NaN        272  881f1a8d91fffff  0.43   \n2    75838  51.332178  12.343082   NaN        454  881f1a8d9bfffff  0.39   \n3    75838  51.324615  12.336922   NaN        294  881f1a8d91fffff  0.59   \n4    75838  51.330267  12.336166   NaN        347  881f1a8d9bfffff  0.93   \n\n   rain  snow    dt_start      dt_end  idle_time_next_day  \n0   NaN   NaN  1609456924  1609459199         1439.000000  \n1   NaN   NaN  1609788468  1609804799          329.533333  \n2   NaN  0.44  1609824851  1609852120         1439.000000  \n3   NaN  0.26  1609852416  1609870109         1439.000000  \n4   NaN   NaN  1609870349  1609891199          452.600000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bike_id</th>\n      <th>lat</th>\n      <th>lng</th>\n      <th>flag</th>\n      <th>idle_time</th>\n      <th>hex_id</th>\n      <th>temp</th>\n      <th>rain</th>\n      <th>snow</th>\n      <th>dt_start</th>\n      <th>dt_end</th>\n      <th>idle_time_next_day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>75838</td>\n      <td>51.331022</td>\n      <td>12.316226</td>\n      <td>NaN</td>\n      <td>37</td>\n      <td>881f1a8dd7fffff</td>\n      <td>2.72</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1609456924</td>\n      <td>1609459199</td>\n      <td>1439.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>75838</td>\n      <td>51.326178</td>\n      <td>12.334760</td>\n      <td>NaN</td>\n      <td>272</td>\n      <td>881f1a8d91fffff</td>\n      <td>0.43</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1609788468</td>\n      <td>1609804799</td>\n      <td>329.533333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>75838</td>\n      <td>51.332178</td>\n      <td>12.343082</td>\n      <td>NaN</td>\n      <td>454</td>\n      <td>881f1a8d9bfffff</td>\n      <td>0.39</td>\n      <td>NaN</td>\n      <td>0.44</td>\n      <td>1609824851</td>\n      <td>1609852120</td>\n      <td>1439.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>75838</td>\n      <td>51.324615</td>\n      <td>12.336922</td>\n      <td>NaN</td>\n      <td>294</td>\n      <td>881f1a8d91fffff</td>\n      <td>0.59</td>\n      <td>NaN</td>\n      <td>0.26</td>\n      <td>1609852416</td>\n      <td>1609870109</td>\n      <td>1439.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>75838</td>\n      <td>51.330267</td>\n      <td>12.336166</td>\n      <td>NaN</td>\n      <td>347</td>\n      <td>881f1a8d9bfffff</td>\n      <td>0.93</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1609870349</td>\n      <td>1609891199</td>\n      <td>452.600000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_points.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "209f3e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_points.to_csv('../data/df_points/df_points_2021.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec05924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}